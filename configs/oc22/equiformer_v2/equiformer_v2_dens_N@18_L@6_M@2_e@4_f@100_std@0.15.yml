trainer: denoising_forces


dataset:
  train:
    format: oc22_lmdb
    src: #/large_experiments/opencatalyst/data/oc22/2022_06_16/s2ef/train_ef
    key_mapping:
      y: energy
      force: forces
    transforms:
      normalizer:
        energy:
          mean: 0.0
          stdev: 25.119809935106424
        forces:
          mean: 0.0
          stdev: 0.14759646356105804
    lin_ref:  #
    oc20_ref: #
  val:
    src: #/large_experiments/opencatalyst/data/oc22/2022_06_16/s2ef/val_id_ood_30k #/large_experiments/opencatalyst/data/oc22/2022_06_16/s2ef/val_id_30k
    # val_id_30k
    lin_ref:  #
    oc20_ref: #
  # test:
  #   src: /large_experiments/opencatalyst/data/oc22/2022_06_16/s2ef/test_id_ef
  #   lin_ref: 


logger:
  name: wandb
  project: equiformer_v2


# for computing statistics of OC22 dataset
compute_stats: False


task:
  prediction_dtype: float32
  # Relaxation hyperparams.
  #relaxation_steps: 300
  #relaxation_fmax: 0.02
  #relax_dataset:
  #  src: /large_experiments/opencatalyst/data/oc22/2022_06_16/is2re/test_ood/
  #relax_opt:
  #  name: lbfgs
  #  maxstep: 0.2
  #  memory: 50
  #  damping: 1.2
  #  alpha: 80.0
  #  traj_dir: 
  

loss_functions:
  - energy:
      fn: mae
      coefficient: 4
  - forces:
      fn: l2mae
      coefficient: 100


evaluation_metrics:
  primary_metric: energy_mae
  metrics:
    energy:
      - mae
    forces:
      - forcesx_mae
      - forcesy_mae
      - forcesz_mae
      - mae
      - cosine_similarity
      - magnitude_error


outputs:
  energy:
    level: system
  forces:
    level: atom
    train_on_free_atoms: True
    eval_on_free_atoms: True


slurm:
  constraint: "volta32gb"


hide_eval_progressbar: False


model:
  name: equiformer_v2_dens

  use_pbc:                  True
  regress_forces:           True
  otf_graph:                True

  max_neighbors:            20
  max_radius:               12.0
  max_num_elements:         90

  num_layers:               18
  sphere_channels:          128
  attn_hidden_channels:     64              # [64, 96] This determines the hidden size of message passing. Do not necessarily use 96.
  num_heads:                8
  attn_alpha_channels:      64              # Not used when `use_s2_act_attn` is True.
  attn_value_channels:      16
  ffn_hidden_channels:      128
  norm_type:                'layer_norm_sh'    # ['rms_norm_sh', 'layer_norm', 'layer_norm_sh']

  lmax_list:                [6]
  mmax_list:                [2]
  grid_resolution:          18              # [18, 16, 14, None] For `None`, simply comment this line.

  num_sphere_samples:       128

  edge_channels:              128
  use_atom_edge_embedding:    True
  share_atom_edge_embedding:  False         # If `True`, `use_atom_edge_embedding` must be `True` and the atom edge embedding will be shared across all blocks.
  use_m_share_rad:            False
  distance_function:          'gaussian'
  num_distance_basis:         512           # not used

  attn_activation:          'silu'
  use_tp_reparam:           False       # [False, True] Whether to use tensor product re-parametrization for SO(2) convolution.
  use_s2_act_attn:          False       # [False, True] Switch between attention after S2 activation or the original EquiformerV1 attention.
  use_attn_renorm:          True        # Attention re-normalization. Used for ablation study.
  ffn_activation:           'silu'      # ['silu', 'swiglu']
  use_gate_act:             False       # [True, False] Switch between gate activation and S2 activation
  use_grid_mlp:             True        # [False, True] If `True`, use projecting to grids and performing MLPs for FFNs.
  use_sep_s2_act:           True        # Separable S2 activation. Used for ablation study.

  alpha_drop:               0.1         # [0.0, 0.1]
  drop_path_rate:           0.1         # [0.0, 0.05]
  proj_drop:                0.0

  weight_init:              'uniform'    # ['uniform', 'normal']

  enforce_max_neighbors_strictly:       False

  use_force_encoding:                   True
  use_noise_schedule_sigma_encoding:    False

  use_energy_lin_ref:                   False
  load_energy_lin_ref:                  False


optim:
  batch_size:               4
  eval_batch_size:          4
  load_balancing:           atoms
  num_workers:              8
  lr_initial:               0.0002

  optimizer:                AdamW
  optimizer_params:
    weight_decay:           0.001
  scheduler:                LambdaLR
  scheduler_params:
    lambda_type:            cosine
    warmup_factor:          0.2
    warmup_epochs:          0.1
    lr_min_factor:          0.01

  max_epochs:               6
  clip_grad_norm:           50
  ema_decay:                0.999
  loss_energy:              mae
  loss_force:               l2mae

  eval_every:               5000

  # for denoising positions
  use_denoising_pos:            True
  denoising_pos_params:
    prob:                       0.5       # probability to switch between denoising positions and S2EF
    fixed_noise_std:            True
    std:                        0.15
    num_steps:                  50
    std_low:                    0.01
    std_high:                   0.2
    corrupt_ratio:              0.5
  denoising_pos_coefficient:    25